<!doctype html>
<html>

<head>

  <title>
    Tanveer Khan
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="https://andrewcharlesjones.github.io/assets/css/main.css">
  <link rel="stylesheet" href="https://andrewcharlesjones.github.io/assets/css/syntax.css">
  <!-- Use Atom -->
  <link type="application/atom+xml" rel="alternate" href="https://tkhan11.github.io/" title="Tanveer Khan" />
  <!-- Use RSS-2.0 -->
  <!--<link href="https://tkhan11.github.io" type="application/rss+xml" rel="alternate" title="Tanveer Khan | CS PhD scholar @ Jamia Millia Islamia"/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
      });
  </script>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-149140730-1', 'auto');
  ga('send', 'pageview');
</script>


  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Market basket analysis using Apriori algorithm| Tanveer Khan</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Market basket analysis using Apriori algorithm" />
<meta name="author" content="Tanveer Khan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="layout: post title: “Market basket analysis using Apriori algorithm” author: “Tanveer Khan” categories: journal blurb: “” img: “” tags: [] —" />
<meta property="og:description" content="layout: post title: “Market basket analysis using Apriori algorithm” author: “Tanveer Khan” categories: journal blurb: “” img: “” tags: [] —" />
<link rel="canonical" href="https://tkhan11.github.io/post/page/3/project-9/index.html" />
<meta property="og:url" content="https://tkhan11.github.io/post/page/3/project-9/index.html" />
<meta property="og:site_name" content="Tanveer Khan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-04-14T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Market basket analysis using Apriori algorithm " />


<!--
<script type="application/ld+json">
{"datePublished":"2021-04-14T00:00:00+00:00","url":"https://tkhan11.github.io/post/page/3/project-9/index.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://tkhan11.github.io/post/page/3/project-7/generalized-pca.html"},"author":{"@type":"Person","name":"Tanveer Khan"},"@context":"https://schema.org"}</script>
 End Jekyll SEO tag -->


</head>



<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="https://tkhan11.github.io/">Tanveer Khan </a>
    <small class="masthead-subtitle"> CS PhD scholar@ Jamia Millia Islamia</small>


   <div class="menu">

     <nav class="menu-content">

         <a href="https://tkhan11.github.io/blog/blog.html">Blog</a>

         <a href="https://tkhan11.github.io/publications/">Publications</a>

       <!--  <a href="https://tkhan11.github.io/publications/files/Tanveer_Khan_CV.pdf">CV</a>
     -->
     </nav>
     
  <nav class="social-icons">

    <a href="https://github.com/tkhan11" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>

    <a href="https://www.suraiyajabin.in/tanveer-ahmed-khan" target="_blank"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a>

    <a href="https://twitter.com/" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>

    <a>tanveer1910377@st.jmi.ac.in</a>

 </nav>



</div>

  </h3>
</header>


    <div class="post-container">
      <h1 style="line-height: 1.2;">
Market basket analysis using Apriori algorithm
</h1>

<p style="text-align: justify">Market basket analysis for finding association rules is a technique to identify underlying relations between different items.
  Take an example of a Super Market where customers can buy variety of items. Usually, there is a pattern in what the customers buy.
  For instance, mothers with babies buy baby products such as milk and diapers.
  Damsels may buy makeup items whereas bachelors may buy beers and chips etc.
  In short, transactions involve a pattern. More profit can be generated if the relationship between the items purchased in different transactions can be identified.</p>

<p style="text-align: justify">For instance, if item A and B are bought together more frequently then several measures can be taken to increase the profit. For example:</p>

    <ul>
      <li>A and B can be placed together so that when a customer buys one of the product he doesn't have to go far away to buy the other product.</li>
      <li>People who buy one of the products can be targeted through an advertisement campaign to buy the other.</li>
      <li>Collective discounts can be offered on these products if the customer buys both of them.</li>
      <li>Both A and B can be packaged and sold together.</li>
    </ul>

<p style="text-align: justify">The process of identifying an associations between products is called association rule mining.</p>

<h2 id="the-exponential-family">Apriori Algorithm</h2>

<p style="text-align: justify"> Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. The apriori algorithm has been designed to operate on databases
   containing transactions, such as purchases by customers of a store. An itemset is considered as "frequent" if it meets a user-specified support threshold. For instance, if the support threshold is set to 0.5 (50%),
   a frequent itemset is defined as a set of items that occur together in at least 50% of all transactions in the database.</p>


<h3 id="the-exponential-family">Concepts related to Apriori algorithm</h3>
<p style="text-align: justify">Here we will discuss some general concepts related to the Apriori algorithm.</p>

<h4 id="the-exponential-family">Support</h4>
<p style="text-align: justify">Support refers to the default popularity of an item and can be calculated by finding number of transactions containing a
  particular item divided by total number of transactions. Suppose we want to find support for item B. This can be calculated as:<br><br>
  <i>Support(B) = (Transactions containing (B))/(Total Transactions)</i>
 </p>

<h4 id="the-exponential-family">Confidence</h4>
<p style="text-align: justify">Confidence refers to the likelihood that an item B is also bought if item A is bought. It can be calculated by finding the number of
  transactions where A and B are bought together, divided by total number of transactions where A is bought. Mathematically, it can be represented as:<br><br>
 <i>Confidence(A→B) = (Transactions containing both (A and B))/(Transactions containing A)</i>
</p>

<h4 id="the-exponential-family">Lift</h4>
<p style="text-align: justify">Lift(A -> B) refers to the increase in the ratio of sale of B when A is sold. Lift(A –> B)
  can be calculated by dividing Confidence(A -> B) divided by Support(B). Mathematically it can be represented as:<br><br>
  <i>Lift(A→B) = (Confidence (A→B))/(Support (B))</i>
</p>






<h2 id="the-exponential-family">Steps Involved in Apriori Algorithm</h2>
<p style="text-align: justify">For large sets of data, there can be hundreds of items in hundreds of thousands transactions. The Apriori algorithm tries to extract rules
 for each possible combination of items. For instance, Lift can be calculated for item 1 and item 2, item 1 and item 3, item 1 and item 4 and
  then item 2 and item 3, item 2 and item 4 and then combinations of items e.g. item 1, item 2 and item 3; similarly item 1, item2, and item 4, and so on.</p>

<p style="text-align: justify">As you can see from the above example, this process can be extremely slow due to the number of combinations.
To speed up the process, we need to perform the following steps:</p>
<ul style="text-align: justify">
  <li>Step 1: Set a minimum value for support and confidence. This means that we are only interested in finding rules for the items
    that have certain default existence (e.g. support) and have a minimum value for co-occurrence with other items (e.g. confidence).</li >
  <li>Step 2: Extract all the subsets having higher value of support than minimum threshold.</li>
  <li>Step 3: Select all the rules from the subsets with confidence value higher than minimum threshold.</li>
  <li>Step 4: Order the rules by descending order of Lift.</li>

</ul>

<h2 id="the-exponential-family">Implementation of Apriori Algorithm in Python</h2>
<p style="text-align: justify">In this section we will use the Apriori algorithm to find rules that describe associations
  between different products given 7500 transactions over the course of a week at a American retail store.
   The dataset can be downloaded from <a href="https://github.com/tkhan11/tkhan11.github.io/blob/master/post/page/3/project-9/items_purchased_data.csv"> here </a>.</p>

<h3 id="the-exponential-family">Import packages</h3>
<p style="text-align: justify">The first step, as always, is to import the required packages. Execute the following script to do so:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
   # import packages
   import pandas as pd
   from mlxtend.frequent_patterns import apriori
   from mlxtend.frequent_patterns import association_rules
 </p>
 </code></pre></div></div>

<h3 id="the-exponential-family">Reading the Dataset</h3>

<p style="text-align: justify">Now let's load the dataset into the working directory and see what we're working with.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  # Read the gorcery data
  items_data= pd.read_csv("./Grocery_data.csv",header=None)
</p>
</code></pre></div></div>

<p style="text-align: justify">Let's call the head() function to see how the dataset looks:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  print("Dataset:", items_data.head(15),"\n")
</p>
</code></pre></div></div>
<p>
  <img src="/images/dataapriori.png" alt="dataapriori">
</p>
<p style="text-align: justify">A snippet of the dataset is shown in the above figure.
  If we carefully examine the data, we can see that there is no header in this datset. Each row corresponds to a transaction and each column
   corresponds to an item (s) purchased in that specific transaction. The NaN tells us that the item represented by the column was not purchased
  in that specific transaction.</p>

<p style="text-align: justify">In this dataset there is no header row. But by default, pd.read_csv function treats first row as header.
For this, we have added "header=None" option to pd.read_csv function, as shown above in the reading the data code snippet.</p>



<h3 id="the-exponential-family">Data Pre-Processing</h3>
<p style="text-align: justify">The Apriori module from "mlxtend" package we are going to use requires our dataset to be in the one-hot encoded form i.e in the form of "0" or "1".
  Currently we have our data in the form of a pandas dataframe. To convert our pandas dataframe to one-hot encoded dataframe, execute the following script:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
# one hot encoding for supplying data in the apriori algorithm
for i, rows in items_data.iterrows():
  labels={}
  uncommons=list( set(unique_items)-set(rows))
  commons=list( set(unique_items).intersection(rows))
  for un in uncommons:
    labels[un] = 0
  for com in commons:
    labels[com] = 1
  encoded_vals.append(labels)

# create a dtaframe for enocoded data
encoded_data = pd.DataFrame(encoded_vals)
print("\nOne hot encoded data:\n", encoded_data.head(10),"\n")
</p>
</code></pre></div></div>

<h3 id="the-exponential-family">Applying Apriori</h3>
<p style="text-align: justify">The next step is to apply the Apriori algorithm on the dataset. To do so, we can use the apriori class that we imported from the mlxtend library</p>

  <p style="text-align: justify">The apriori class requires some parameter values to work. The first parameter is the one-hot encoded dataframe that we want to extract rules from.
  The second parameter is the min_support parameter. This parameter is used to select the items with support values greater than the value specified by the parameter.
   Next, the use_colnames parameter that If True, uses the DataFrames' column names in the returned DataFrame instead of column indices. Other parameter max_len
   takes the value for maximum length of the itemsets generated. Finally, the verboe parameter shows the number of iterations. Executing the following script we can have our frequent itemsets generated:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  frequent_items = apriori(encoded_data, min_support=0.0085, use_colnames=True, verbose=1)
</p>
</code></pre></div></div>


<p style="text-align: justify">Here, we will print the top 15 frequent itemsets generated susing apriori algorithm.</p>


<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  print("Top 15 frequent items:\n",frequent_items.head(15),"\n")
</p>
</code></pre></div></div>

<p style="text-align: justify">Figure below shows the frequent itemsets with their support values.</p>

<p>
  <img src="/images/freq.png" alt="freq">
</p>

<p style="text-align: justify">For generating the association rules for the itemsets generated using apriori algorithm we will use the 'association_rules' class from the
"mlxtend" package. The association_rules class takes 'frequent_ itemsets' dataframe, 'metrics' and 'min threshold' values as some parameters. Executing the following script for generating the association rules:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  association_rule_generated_confidence= association_rules(frequent_items, metric="confidence", min_threshold=0.25)
</p>
</code></pre></div></div>

<p style="text-align: justify">Here, we will print the association_rules generated using "confidence" as a metric with 0.25 as a threshold value.</p>


<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  print("association rules generated through confidence metrics:\n", association_rule_generated_confidence.head(15),"\n")
</p>
</code></pre></div></div>

<p style="text-align: justify">Figure below shows the association rules generated with lift, confidence, leverage, and support values.</p>

<p>
  <img src="/images/conf.png" alt="conf">
</p>



<h2 id="the-exponential-family">Conclusion</h2>
<p style="text-align: justify">
  Association rule mining algorithms such as Apriori are very useful for finding associations between our data items. They are easy to implement and have high generalizability.
</p>

<p style="text-align: justify">
  However Appriori algorithm suffer from issues like, the size of itemset from candidate generation could be extremely large
  and lots of time gets wasted on counting the support since we have to scan the itemset database over and over again till the algorithm converges.
</p>

<!-- <span class="post-date">


  May
  10th,
  2021
  by

    Tanveer Khan

</span> -->

<!--
 <div class="post-date"></div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=Market basket analysis using Apriori algorithms&amp;url="https://tkhan11.github.io/post/project-4/index.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u="https://tkhan11.github.io/post/page/project-4/index.html"&amp;title="Market basket analysis using Apriori algorithm " target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
  </div>
</div>

-->

<!-- <div class="related">
  <h1 ></h1>

  <ul class="related-posts">

  </ul>
</div>
 -->



    </div>

    <footer class="footer">
  <!--


    <a href="https://github.com/tkhan11" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>




    <a href="https://suraiyajabin.in/tanveer-ahmed-khan" target="_blank"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a>




    <a href="https://twitter.com/" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>




    <a>tanveer1910377@jmi.ac.in</a>

 -->
  <div class="post-date"><a href="https://tkhan11.github.io/about/">Tanveer Khan | CS PhD scholar @ Jamia Millia Islamia</a></div>
</footer>

  </div>

</body>
</html>

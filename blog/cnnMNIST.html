<!doctype html>
<html>

<head>

  <title>
    Tanveer Ahmed Khan D4DI
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/dist/css/main.css">
  <link rel="stylesheet" href="/dist/css/syntax.css">
  <!-- Use Atom -->
  <link type="application/atom+xml" rel="alternate" href="https://tkhan11.github.io/" title="Tanveer Khan" />
  <!-- Use RSS-2.0 -->
  <!--<link href="https://tkhan11.github.io" type="application/rss+xml" rel="alternate" title="Tanveer Khan | CS PhD scholar @ Jamia Millia Islamia"/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
      });
  </script>

 <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PND0KQF3PH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PND0KQF3PH');
</script>

  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>CNN  for handwritten digit recognition problem on MNIST  dataset| Tanveer Khan</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Data Visualization in Python " />
<meta name="author" content="Tanveer Khan" />
<meta name="keywords" content="D4DI, Data4DerivingInsights">
<meta property="og:locale" content="en_US" />
<meta name="description" content="layout: post title: “CNN for handwritten digit recognition problem on MNIST  dataset ” author: “Tanveer Khan” categories: journal blurb: “” img: “” tags: [] —" />
<meta property="og:description" content="layout: post title: “CNN for handwritten digit recognition problem on MNIST  dataset ” author: “Tanveer Khan” categories: journal blurb: “” img: “” tags: [] —" />
<link rel="canonical" href="https://tkhan11.github.io/blog/cnnMNIST.html" />
<meta property="og:url" content="https://tkhan11.github.io/blog/cnnMNIST.html" />
<meta property="og:site_name" content="Tanveer Khan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-14T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="CNN for handwritten digit recognition problem on MNIST  dataset" />

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3260725685986309"
     crossorigin="anonymous"></script>
     
<script type="application/ld+json">
{"datePublished":"2021-01-14T00:00:00+00:00","url":"https://tkhan11.github.io/blog/cnnMNIST.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://tkhan11.github.io/blog/cnnMNIST.html"},"author":{"@type":"Person","name":"Tanveer Khan"},"@context":"https://schema.org"}</script>



</head>



<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="https://tkhan11.github.io/">Tanveer Khan </a>
    <small class="masthead-subtitle"> Data Scientist @ NextGen Invent | Research Scholar @ Jamia Millia Islamia</small>

    <div class="menu">

      <nav class="menu-content">

          <a href="https://tkhan11.github.io/blog/blog.html">Blog</a>

          <a href="https://tkhan11.github.io/publications/">Research</a>

        <!--  <a href="https://tkhan11.github.io/publications/files/Tanveer_Khan_CV.pdf">CV</a>
      -->
      </nav>
      
  <nav class="social-icons">

    <a href="https://github.com/tkhan11" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>

    <a href="https://www.suraiyajabin.in/tanveer-ahmed-khan" target="_blank"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a>

    <a href="https://www.linkedin.com/in/takhan11/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
    
    <a>tanveerkhand4di@gmail.com</a>

 </nav>



</div>


  </h3>
</header>


    <div class="post-container">
      <h1 style="line-height: 1.2;">
  CNN for handwritten digit recognition problem on MNIST  dataset
</h1>

<p>
<img src="/images/MNISTdigit.png" alt="MNISTdigit">
</p>


<p style="text-align: justify">Convolutional Neural Networks (CNNs) are the current state-of-art architecture for image classification task. Whether it is facial recognition, self driving cars or object detection, CNNs are being used everywhere. In this post, a simple 2-D
  Convolutional Neural Network (CNN) model is designed using keras with tensorflow backend for the well known MNIST digit recognition task. The whole work flow can be described as:</p>

<dl>

  <dd>1.  Preparing the data</dd>
  <dd>2.  Building and compiling of the model</dd>
  <dd>3.  Training and evaluating the model</dd>
  <dd>4.  Saving the model to disk for reuse</dd>
</dl>


    <h2 id="the-exponential-family">Preparing the data</h2>
	<p style="text-align: justify">The data set used here is MNIST dataset as mentioned above. The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits (0 to 9). The database contains 60,000
     training images and 10,000 testing images each of size 28x28. The first step is to load the dataset, which can be easily done through the keras api.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  import keras
  from keras.datasets import mnist
  #load mnist dataset
  (X_train, y_train), (X_test, y_test) = mnist.load_data() #everytime loading data won't be so easy :)</p>
</code></pre></div></div>

<p style="text-align: justify">Here X_train contains 60,000 training images’ data each of size 28x28 and y_train contains their corresponding labels. Similarly, X_test contains 10,000 testing images’ data each of dimension
28x28 and y_test contains their corresponding labels. Let’s visualize few data from training to get a better idea about the purpose of the deep learning model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
  import matplotlib.pyplot as plt
  fig = plt.figure()
  for i in range(9):
    plt.subplot(3,3,i+1)
    plt.tight_layout()
    plt.imshow(X_train[i], cmap='gray', interpolation='none')
    plt.title("Digit: {}".format(y_train[i]))
    plt.xticks([])
    plt.yticks([])
  fig
</p>
</code></pre></div></div>

<p><img src="/images/mnist.png" alt="mnist" /></p>

<p style="text-align: justify">As can be seen here, at left top corner the image of ‘5’ is stored is X_train[0] and y_train[0] contains label ‘5’.
Our deep learning model should be able to only take the handwritten image and predict the actual digit written.</p>

<p style="text-align: justify">Now, to prepare the data we need some processing on the images like resizing images, normalizing the pixel values etc.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
#reshaping
#this assumes our data format
#For 3D data, "channels_last" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while
#"channels_first" assumes (channels, conv_dim1, conv_dim2, conv_dim3).
if k.image_data_format() == 'channels_first':
    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)
#more reshaping
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print('X_train shape:', X_train.shape) #X_train shape: (60000, 28, 28, 1)
</p>
</code></pre></div></div>

<p style="text-align: justify">After doing the necessary processing on the image informations, the label data i.e. y_train and y_test need to be converted into categorical formats like label ‘3’ should be converted to a vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] for model building.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
import keras
#set number of categories
num_category = 10
# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_category)
y_test = keras.utils.to_categorical(y_test, num_category)
</p>
</code></pre></div></div>


<h2 id="the-exponential-family">Building and compiling of the model</h2>

<p style="text-align: justify">After the data is ready to be fed to the model, we need to define the architecture of the model and compile it with necessary optimizer function, loss function and performance metrics.</p>

<p style="text-align: justify">The architecture followed here is 2 convolution layers followed by pooling layer, a fully connected layer and softmax layer respectively. Multiple filters are used at each convolution layer, for different types of feature extraction. One intuitive explanation can be if first filter helps in detecting the straight lines in the image, second filter will help in detecting circles and so on.</p>

<p style="text-align: justify">After both maxpooling and fully connected layer, dropout is introduced as regularization in our model to reduce over-fitting problem.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
##model building
model = Sequential()
#convolutional layer with rectified linear unit activation
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
#32 convolution filters used each of size 3x3
#again
model.add(Conv2D(64, (3, 3), activation='relu'))
#64 convolution filters used each of size 3x3
#choose the best features via pooling
model.add(MaxPooling2D(pool_size=(2, 2)))
#randomly turn neurons on and off to improve convergence
model.add(Dropout(0.25))
#flatten since too many dimensions, we only want a classification output
model.add(Flatten())
#fully connected to get all relevant data
model.add(Dense(128, activation='relu'))
#one more dropout for convergence' sake :)
model.add(Dropout(0.5))
#output a softmax to squash the matrix into output probabilities
model.add(Dense(num_category, activation='softmax'))
</p>
</code></pre></div></div>

<p style="text-align: justify">After the architecture of the model is defined, the model needs to be compiled. Here, we are using categorical_crossentropy loss function as it is a multi-class classification problem. Since all the labels carry similar weight we prefer accuracy as performance metric. A popular gradient descent technique called AdaDelta is used for optimization of the model parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad
#categorical ce since we have multiple classes (10)
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
</p>
</code></pre></div></div>

<h2 id="the-exponential-family">Training and evaluating the model</h2>

<p style="text-align: justify">After the model architecture is defined and compiled, the model needs to be trained with training data to be able to recognize the handwritten digits. Hence we will fit the model with X_train and y_train.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
batch_size = 128
num_epoch = 10
#model training
model_log = model.fit(X_train, y_train,
          batch_size=batch_size,
          epochs=num_epoch,
          verbose=1,
          validation_data=(X_test, y_test))
</p>
</code></pre></div></div>

<p style="text-align: justify">Here, one epoch means one forward and one backward pass of all the training samples. Batch size implies number of training samples in one forward/backward pass.</p>

<p style="text-align: justify">Now the trained model needs to be evaluated in terms of performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
score = model.evaluate(X_test, y_test, verbose=0)
print('Test loss:', score[0]) #Test loss: 0.0296396646054
print('Test accuracy:', score[1]) #Test accuracy: 0.9904
</p>
</code></pre></div></div>

<p style="text-align: justify">Test accuracy 99%+ implies the model is trained well for prediction. If we visualize the whole training log,
then with more number of epochs the loss and accuracy of the model on training and testing data converged thus making the model a stable one.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
import os
# plotting the metrics
fig = plt.figure()
plt.subplot(2,1,1)
plt.plot(model_log.history['acc'])
plt.plot(model_log.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.subplot(2,1,2)
plt.plot(model_log.history['loss'])
plt.plot(model_log.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.tight_layout()
fig
</p>
</code></pre></div></div>

<p><img src="/images/plot.png" alt="plot" /></p>

<h2 id="the-exponential-family">Saving the model to disk for reuse</h2>

<p style="text-align: justify">Now, the trained model needs to be serialized. The architecture or structure of the model will be stored in a json file and the weights will be stored in hdf5 file format.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<p>
#Save the model
# serialize model to JSON
model_digit_json = model.to_json()
with open("model_digit.json", "w") as json_file:
    json_file.write(model_digit_json)
# serialize weights to HDF5
model.save_weights("model_digit.h5")
print("Saved model to disk")
</p>
</code></pre></div></div>

<p style="text-align: justify">Hence the saved model can be reused later or easily ported to other environments too.</p>

<h2 id="references">References</h2>

<ul  style="text-align: justify">

<li>Ahlawat, S., Choudhary, A., Nayyar, A., Singh, S., & Yoon, B. (2020). Improved handwritten digit recognition using convolutional neural networks (CNN). Sensors, 20(12), 3344.</li>

 <li>Teow, M. Y. (2017, October). A minimal convolutional neural network for handwritten digit recognition. In 2017 7th IEEE International Conference on System Engineering and Technology (ICSET) (pp. 171-176). IEEE.</li>

</ul>


    </div>

    <footer class="footer">
  <!--


    <a href="https://github.com/tkhan11" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>




    <a href="https://suraiyajabin.in/tanveer-ahmed-khan" target="_blank"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a>




    <a href="https://twitter.com/" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>




    <a>tanveer1910377@jmi.ac.in</a>

 -->
  <div class="post-date"><a href="https://tkhan11.github.io/about/">Tanveer Khan | Data Scientist @ NextGen Invent | Research Scholar @ Jamia Millia Islamia</a></div>
</footer>

  </div>

</body>
</html>
